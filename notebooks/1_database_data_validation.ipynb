{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeiDS/Test_for_pyspark/blob/main/notebooks/1_database_data_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-HWblpWRHhhx"
      },
      "source": [
        "# Database data validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "re6rzPM8Hhh2"
      },
      "source": [
        "In this notebook, we will see how we can use the great_expectations package to validate data in our database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9yDg2PASHhh3"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NatanMish/data_validation/blob/main/notebooks/1_database_data_validation.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PqG8vEpSHhh4"
      },
      "source": [
        "#### Install the required packages and import them to the notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3yIJFFQbHhh5",
        "outputId": "f9d4b94a-3cda-43ee-e5f2-53211aae2edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting great_expectations\n",
            "  Downloading great_expectations-0.15.18-py3-none-any.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (2.11.3)\n",
            "Requirement already satisfied: tqdm>=4.59.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (4.64.0)\n",
            "Collecting makefun<2,>=1.7.0\n",
            "  Downloading makefun-1.14.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: mistune>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (0.8.4)\n",
            "Collecting jsonpatch>=1.22\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (7.7.1)\n",
            "Requirement already satisfied: nbformat>=5.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (4.12.0)\n",
            "Requirement already satisfied: altair<5,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (4.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (1.1.0)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 67.2 MB/s \n",
            "\u001b[?25hCollecting Ipython>=7.16.3\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2021.3 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (2022.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (7.1.2)\n",
            "Collecting colorama>=0.4.3\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: jsonschema>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (4.3.3)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (1.5.1)\n",
            "Collecting cryptography>=3.2\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 27.5 MB/s \n",
            "\u001b[?25hCollecting notebook>=6.4.10\n",
            "  Downloading notebook-6.4.12-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting pyparsing<3,>=2.4\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml<0.17.18,>=0.16\n",
            "  Downloading ruamel.yaml-0.17.17-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from great_expectations) (21.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from great_expectations) (1.21.6)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair<5,>=4.0.0->great_expectations) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair<5,>=4.0.0->great_expectations) (0.12.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.2->great_expectations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.2->great_expectations) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->great_expectations) (3.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (2.0.10)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (4.4.2)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (2.6.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from Ipython>=7.16.3->great_expectations) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->great_expectations) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->great_expectations) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->great_expectations) (5.3.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->great_expectations) (1.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->great_expectations) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->great_expectations) (5.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->Ipython>=7.16.3->great_expectations) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->great_expectations) (2.0.1)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.5.1->great_expectations) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.5.1->great_expectations) (5.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.5.1->great_expectations) (0.18.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.0->great_expectations) (2.16.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.0->great_expectations) (4.11.1)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.7/dist-packages (from notebook>=6.4.10->great_expectations) (5.6.1)\n",
            "Collecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook>=6.4.10->great_expectations) (23.2.1)\n",
            "Collecting nest-asyncio>=1.5\n",
            "  Downloading nest_asyncio-1.5.5-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=6.4.10->great_expectations) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from notebook>=6.4.10->great_expectations) (0.13.3)\n",
            "Collecting prometheus-client\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting tornado>=4.2\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[K     |████████████████████████████████| 423 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations) (5.0.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->Ipython>=7.16.3->great_expectations) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython>=7.16.3->great_expectations) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython>=7.16.3->great_expectations) (1.15.0)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->great_expectations) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->great_expectations) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->great_expectations) (2022.6.15)\n",
            "Collecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 49.2 MB/s \n",
            "\u001b[?25hCollecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=5->notebook>=6.4.10->great_expectations) (0.5.1)\n",
            "Installing collected packages: tornado, matplotlib-inline, jedi, Ipython, argon2-cffi-bindings, prometheus-client, nest-asyncio, argon2-cffi, notebook, urllib3, ruamel.yaml.clib, pyparsing, jsonpointer, ruamel.yaml, makefun, jsonpatch, cryptography, colorama, great-expectations\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: Ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 5.3.1\n",
            "    Uninstalling notebook-5.3.1:\n",
            "      Successfully uninstalled notebook-5.3.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.3.0, but you have notebook 6.4.12 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Ipython-7.34.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 colorama-0.4.5 cryptography-37.0.4 great-expectations-0.15.18 jedi-0.18.1 jsonpatch-1.32 jsonpointer-2.3 makefun-1.14.0 matplotlib-inline-0.1.6 nest-asyncio-1.5.5 notebook-6.4.12 prometheus-client-0.14.1 pyparsing-2.4.7 ruamel.yaml-0.17.17 ruamel.yaml.clib-0.2.6 tornado-6.2 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "pyparsing",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U great_expectations pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1fzeSQ99Hhh6"
      },
      "outputs": [],
      "source": [
        "# import the required packages\n",
        "import great_expectations as ge\n",
        "from great_expectations.core.batch import RuntimeBatchRequest\n",
        "from great_expectations.profile.user_configurable_profiler import (\n",
        "    UserConfigurableProfiler,\n",
        ")\n",
        "from great_expectations.checkpoint import SimpleCheckpoint\n",
        "from ruamel import yaml\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XisHL3a6Hhh7"
      },
      "source": [
        "[![Great Expectations](https://docs.greatexpectations.io/img/great-expectations-long-logo.svg)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RuamH6ZkHhh7"
      },
      "source": [
        "Named after the famous 19th century novel, Great Expectations is a shared, open sourced package for data quality. It helps eliminate pipeline debt, through data testing, documentation, and profiling. It is a tool for data scientists, data engineers, and data analysts to validate data. GE has many useful integrations and can be connected directly to SQL databases, Apache Spark, Apache Airflow, Bigquery, and more. In this tutorial, we will validate a database hosted on a  local file system, but the process for a cloud file system such as a Data Lake, Azure Blob Storage, GCP bucket or AWS S3 is almost identical.\n",
        "\n",
        "**Terminology**\n",
        "1. *Data Context* - The primary entry point for a Great Expectations deployment, with configurations and methods for all supporting components.\n",
        "\n",
        "2. *Data Source* - Provides a standard API for accessing and interacting with data from a wide variety of source systems.\n",
        "\n",
        "3. *Data Asset* - A collection of records within a Datasource which is usually named based on the underlying data system and sliced to correspond to a desired specification.\n",
        "\n",
        "4. *Expectation Suite* - A collection of verifiable assertions about data.\n",
        "\n",
        "5. *Validation* - The act of applying an Expectation Suite to a Batch.\n",
        "\n",
        "6. *Batch Identifier* - contains information that uniquely identifies a specific batch from the Data Asset, such as the delivery date or query time.\n",
        "\n",
        "7. *Data Connector* - Provides the configuration details based on the source data system which are needed by a Datasource to define Data Assets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "u_NIVoamHhh8"
      },
      "source": [
        "### 1. Create a Data Context\n",
        "\n",
        "We will now create a data context, which is the first step in setting up Great Expectations for our project. Creating a data context is actually most easily done in bash using the great_expectations CLI. Run the shell command below and this will initialize a new data context in the current directory. The `echo y` bit is used to suppress the interactive prompt. You will now see a new directory called `great_expectations` created in your current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EYNohLwjHhh9",
        "outputId": "25cb5d2b-5602-4b47-c74c-a06bdb574e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using v3 (Batch Request) API\u001b[0m\n",
            "\u001b[36m\n",
            "  ___              _     ___                  _        _   _\n",
            " / __|_ _ ___ __ _| |_  | __|_ ___ __  ___ __| |_ __ _| |_(_)___ _ _  ___\n",
            "| (_ | '_/ -_) _` |  _| | _|\\ \\ / '_ \\/ -_) _|  _/ _` |  _| / _ \\ ' \\(_-<\n",
            " \\___|_| \\___\\__,_|\\__| |___/_\\_\\ .__/\\___\\__|\\__\\__,_|\\__|_\\___/_||_/__/\n",
            "                                |_|\n",
            "             ~ Always know what to expect from your data ~\n",
            "\u001b[0m\u001b[0m\n",
            "Let's create a new Data Context to hold your project configuration.\n",
            "\n",
            "Great Expectations will create a new directory with the following structure:\n",
            "\n",
            "    great_expectations\n",
            "    |-- great_expectations.yml\n",
            "    |-- expectations\n",
            "    |-- checkpoints\n",
            "    |-- plugins\n",
            "    |-- .gitignore\n",
            "    |-- uncommitted\n",
            "        |-- config_variables.yml\n",
            "        |-- data_docs\n",
            "        |-- validations\n",
            "\n",
            "OK to proceed? [Y/n]: \n",
            "================================================================================\n",
            "\u001b[0m\n",
            "\u001b[36mCongratulations! You are now ready to customize your Great Expectations configuration.\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[36mYou can customize your configuration in many ways. Here are some examples:\u001b[0m\n",
            "\n",
            "  \u001b[36mUse the CLI to:\u001b[0m\n",
            "    - Run `\u001b[32mgreat_expectations datasource new\u001b[0m` to connect to your data.\n",
            "    - Run `\u001b[32mgreat_expectations checkpoint new <checkpoint_name>\u001b[0m` to bundle data with Expectation Suite(s) in a Checkpoint for later re-validation.\n",
            "    - Run `\u001b[32mgreat_expectations suite --help\u001b[0m` to create, edit, list, profile Expectation Suites.\n",
            "    - Run `\u001b[32mgreat_expectations docs --help\u001b[0m` to build and manage Data Docs sites.\n",
            "\n",
            "  \u001b[36mEdit your configuration in great_expectations.yml to:\u001b[0m\n",
            "    - Move Stores to the cloud\n",
            "    - Add Slack notifications, PagerDuty alerts, etc.\n",
            "    - Customize your Data Docs\n",
            "\n",
            "\u001b[36mPlease see our documentation for more configuration options!\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!echo y | great_expectations init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qai1JicXHhh-"
      },
      "source": [
        "After running the init command, your great_expectations directory will contain all the important components of a local Great Expectations deployment. This is what the directory structure looks like:\n",
        "\n",
        "- `great_expectations.yml` contains the main configuration of your deployment.\n",
        "The expectations directory stores all your Expectations as JSON files. If you want to store them somewhere else, you can change that later.\n",
        "\n",
        "- The `plugins/` directory holds code for any custom plugins you develop as part of your deployment.\n",
        "\n",
        "- The `uncommitted/` directory contains files that shouldn’t live in version control. It has a .gitignore configured to exclude all its contents from version control. The main contents of the directory are:\n",
        "    1. `uncommitted/config_variables.yml`, which holds sensitive information, such as database credentials and other secrets.\n",
        "    2. `uncommitted/data_docs`, which contains Data Docs generated from Expectations, Validation Results, and other metadata.\n",
        "    3. `uncommitted/validations`, which holds Validation Results generated by Great Expectations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VK21zQ7uHhh-"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://docs.greatexpectations.io/assets/images/data_context_does_for_you-df2eca32d0152ead16cccd5d3d226abb.png\" width=\"1000\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "L7iFjDmXHhh_"
      },
      "source": [
        "### 2. Create a Data Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pU8zdTrlHhh_"
      },
      "outputs": [],
      "source": [
        "# We will start by reading in the GE data context we have created in the previous step\n",
        "context = ge.get_context()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "H4bn7rexHhh_"
      },
      "source": [
        "Now we will script a yaml file to create a data source. We will need the following configuration parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "p_oKGmWYHhh_"
      },
      "outputs": [],
      "source": [
        "datasource_name = \"house_prices\"\n",
        "# Data Source - Provides a standard API for accessing and interacting with data from a wide variety of source systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KP_6s3pXHhiA"
      },
      "outputs": [],
      "source": [
        "execution_engine = \"PandasExecutionEngine\"  # alternatively we can use SparkExecutionEngine for PySpark oriented\n",
        "# projects or SqlAlchemyExecutionEngine for creating a SQL database data source.\n",
        "data_directory = \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3swY7wd0HhiA"
      },
      "outputs": [],
      "source": [
        "data_asset_name = f\"{datasource_name}_survey_2006\"\n",
        "# Data Asset - A collection of records within a Datasource which is usually named based on the underlying data system and sliced to correspond to a desired specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NbXICyMMHhiA"
      },
      "outputs": [],
      "source": [
        "runtime_data_connector_name = \"runtime_batch_files_connector\"\n",
        "# Data Connector - Provides the configuration details based on the source data system which are needed by a Datasource to define Data Assets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FNbQpBfLHhiB"
      },
      "outputs": [],
      "source": [
        "batch_identifier_name = \"pipeline_step\"\n",
        "# Batch Identifier - contains information that uniquely identifies a specific batch from the Data Asset, such as the delivery date or query time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "89mZakLuHhiB"
      },
      "outputs": [],
      "source": [
        "datasource_config = {\n",
        "    \"name\": datasource_name,\n",
        "    \"class_name\": \"Datasource\",\n",
        "    \"module_name\": \"great_expectations.datasource\",\n",
        "    \"execution_engine\": {\n",
        "        \"module_name\": \"great_expectations.execution_engine\",\n",
        "        \"class_name\": execution_engine,\n",
        "    },\n",
        "    \"data_connectors\": {\n",
        "        runtime_data_connector_name: {\n",
        "            \"class_name\": \"RuntimeDataConnector\",\n",
        "            \"module_name\": \"great_expectations.datasource.data_connector\",\n",
        "            \"assets\": {\n",
        "              data_asset_name: {\n",
        "                \"class_name\": \"Asset\",\n",
        "                \"batch_identifiers\": [batch_identifier_name],\n",
        "                \"module_name\": \"great_expectations.datasource.data_connector.asset\"}}\n",
        "        },\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iHETWB8yHhiB",
        "outputId": "ff8d903b-ab86-4d48-8ab7-5c6a583dfd26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to instantiate class from config...\n",
            "\tInstantiating as a Datasource, since class_name is Datasource\n",
            "\tSuccessfully instantiated Datasource\n",
            "\n",
            "\n",
            "ExecutionEngine class name: PandasExecutionEngine\n",
            "Data Connectors:\n",
            "\truntime_batch_files_connector:RuntimeDataConnector\n",
            "\n",
            "\truntime_batch_files_connector : RuntimeDataConnector\n",
            "\n",
            "\tAvailable data_asset_names (1 of 1):\n",
            "\t\thouse_prices_survey_2006 (0 of 0): []\n",
            "\n",
            "\tUnmatched data_references (0 of 0):[]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<great_expectations.datasource.new_datasource.Datasource at 0x7f845ea6ddd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Test that the configuration is valid\n",
        "context.test_yaml_config(yaml.dump(datasource_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uHG6QhkdHhiC",
        "outputId": "83e57f97-bfa0-4f7f-c4e3-21b94d7abbcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<great_expectations.datasource.new_datasource.Datasource at 0x7f845f2d02d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# If the configuration is valid, we can create the datasource\n",
        "context.add_datasource(**datasource_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zBzjYnAyHhiC",
        "outputId": "7edbbefb-99c1-440c-a25c-75bf286db773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'Datasource',\n",
              "  'data_connectors': {'runtime_batch_files_connector': {'class_name': 'RuntimeDataConnector',\n",
              "    'assets': {'house_prices_survey_2006': {'batch_identifiers': ['pipeline_step'],\n",
              "      'class_name': 'Asset',\n",
              "      'module_name': 'great_expectations.datasource.data_connector.asset'}},\n",
              "    'module_name': 'great_expectations.datasource.data_connector'}},\n",
              "  'execution_engine': {'class_name': 'PandasExecutionEngine',\n",
              "   'module_name': 'great_expectations.execution_engine'},\n",
              "  'module_name': 'great_expectations.datasource',\n",
              "  'name': 'house_prices'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Now we can see that the datasource was created.\n",
        "context.list_datasources()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "J1uG6dRqHhiC"
      },
      "source": [
        "### 3. Create an Expectation Suite\n",
        "Expectations are the core of Great Expectations. They are the assertions that are used to validate data. Let's create an expectation suite which is a collection of expectations. This diagram below shows how we can define good expectations for our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CKXRyunlHhiD"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://docs.greatexpectations.io/assets/images/where_expectations_come_from-b3504cf51ad304c8e4a73677a0e73156.png\" width=\"1000\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YoPSG2AhHhiD"
      },
      "source": [
        "We will create expectations while exploring the data in the notebook. The method below behaves  exactly the same as `pandas.read_csv`. Similarly wrapped versions of other pandas methods (`read_excel`, `read_table`, `read_parquet`, `read_pickle`, `read_json`, etc.) are also available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "q7nWB0wgHhiD"
      },
      "outputs": [],
      "source": [
        "house_data = ge.read_csv(\"https://github.com/NatanMish/data_validation/blob/a77b247b25c6622ce0c8f8cbc505228161c31a3c/data/train.csv?raw=true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZcyH93L5HhiD",
        "outputId": "d727270d-88a1-4835-a155-8b833bf7c85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-312d789a-4dff-4869-860c-800e537c10e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-312d789a-4dff-4869-860c-800e537c10e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-312d789a-4dff-4869-860c-800e537c10e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-312d789a-4dff-4869-860c-800e537c10e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# The house_data variable is a pandas dataframe with all the methods and properties we know and love. We can use the `head` method to see the\n",
        "# first few rows of the data.\n",
        "house_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aDMU2scOHhiE"
      },
      "outputs": [],
      "source": [
        "# beyond the Pandas methods and properties, we can use GE's expectations methods to define expectations. \n",
        "# In Jupyter, type in `house_data.expect` and press tab to see the list of available expectations.\n",
        "dir(house_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qfHWSAXiHhiE",
        "outputId": "3bc01a82-b8dc-48c0-8b1e-2980acb23cc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"meta\": {},\n",
              "  \"expectation_config\": {\n",
              "    \"kwargs\": {\n",
              "      \"column\": \"Id\",\n",
              "      \"result_format\": \"BASIC\"\n",
              "    },\n",
              "    \"meta\": {},\n",
              "    \"expectation_type\": \"expect_column_to_exist\"\n",
              "  },\n",
              "  \"exception_info\": {\n",
              "    \"raised_exception\": false,\n",
              "    \"exception_traceback\": null,\n",
              "    \"exception_message\": null\n",
              "  },\n",
              "  \"result\": {},\n",
              "  \"success\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Let's create a few example expectations and see if they are valid on this dataset.\n",
        "house_data.expect_column_to_exist(\"Id\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_data.expect_column_to_exist(\"Id\").success"
      ],
      "metadata": {
        "id": "RmGWtO9dtdbN",
        "outputId": "4f2c0852-c638-4f62-c959-e89a3a5af029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1lFhgd4mHhiE"
      },
      "source": [
        "Notice the `\"success\": true` key in the result dictionary, this means the expectation is valid for this data source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "07rkBxVWHhiE",
        "outputId": "b230982e-1ab0-44e9-9bb3-d8556a340f6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"meta\": {},\n",
              "  \"expectation_config\": {\n",
              "    \"kwargs\": {\n",
              "      \"column\": \"Id\",\n",
              "      \"result_format\": \"BASIC\"\n",
              "    },\n",
              "    \"meta\": {},\n",
              "    \"expectation_type\": \"expect_column_values_to_be_unique\"\n",
              "  },\n",
              "  \"exception_info\": {\n",
              "    \"raised_exception\": false,\n",
              "    \"exception_traceback\": null,\n",
              "    \"exception_message\": null\n",
              "  },\n",
              "  \"result\": {\n",
              "    \"element_count\": 1460,\n",
              "    \"missing_count\": 0,\n",
              "    \"missing_percent\": 0.0,\n",
              "    \"unexpected_count\": 0,\n",
              "    \"unexpected_percent\": 0.0,\n",
              "    \"unexpected_percent_total\": 0.0,\n",
              "    \"unexpected_percent_nonmissing\": 0.0,\n",
              "    \"partial_unexpected_list\": []\n",
              "  },\n",
              "  \"success\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "house_data.expect_column_values_to_be_unique(\"Id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mFaELo_IHhiE"
      },
      "source": [
        "The expectation above checked the contents of the column, hence we got a few other useful metrics, showing how many \n",
        "rows were inspected, how many were missing etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2ZW6fnykHhiG",
        "outputId": "f8c90071-bf47-478d-9506-c5aed4a06979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"meta\": {},\n",
              "  \"expectation_config\": {\n",
              "    \"kwargs\": {\n",
              "      \"column\": \"SalePrice\",\n",
              "      \"min_value\": 0,\n",
              "      \"max_value\": 100000,\n",
              "      \"result_format\": \"BASIC\"\n",
              "    },\n",
              "    \"meta\": {},\n",
              "    \"expectation_type\": \"expect_column_max_to_be_between\"\n",
              "  },\n",
              "  \"exception_info\": {\n",
              "    \"raised_exception\": false,\n",
              "    \"exception_traceback\": null,\n",
              "    \"exception_message\": null\n",
              "  },\n",
              "  \"result\": {\n",
              "    \"observed_value\": 755000,\n",
              "    \"element_count\": 1460,\n",
              "    \"missing_count\": null,\n",
              "    \"missing_percent\": null\n",
              "  },\n",
              "  \"success\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# This expectation should fail, lets see what happens:\n",
        "house_data.expect_column_max_to_be_between(\"SalePrice\", 0, 100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "F5ItLs3KHhiH"
      },
      "source": [
        "The returned dictionary shows that the expectation is not valid, and the value observed that is not in the expected range.\n",
        "Here are a few more useful expectation definitions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% mdhhome_data.expect_column_distinct_values_to_be_in_set\n"
        },
        "id": "p_xfEuDbHhiH",
        "outputId": "73679465-4001-4cb8-8d6a-c9f6d35d83b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"meta\": {},\n",
              "  \"expectation_config\": {\n",
              "    \"kwargs\": {\n",
              "      \"column\": \"MSZoning\",\n",
              "      \"value_set\": [\n",
              "        \"C (all)\",\n",
              "        \"FV\",\n",
              "        \"RH\",\n",
              "        \"RL\",\n",
              "        \"RM\"\n",
              "      ],\n",
              "      \"result_format\": \"BASIC\"\n",
              "    },\n",
              "    \"meta\": {},\n",
              "    \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\"\n",
              "  },\n",
              "  \"exception_info\": {\n",
              "    \"raised_exception\": false,\n",
              "    \"exception_traceback\": null,\n",
              "    \"exception_message\": null\n",
              "  },\n",
              "  \"result\": {\n",
              "    \"observed_value\": [\n",
              "      \"C (all)\",\n",
              "      \"FV\",\n",
              "      \"RH\",\n",
              "      \"RL\",\n",
              "      \"RM\"\n",
              "    ],\n",
              "    \"element_count\": 1460,\n",
              "    \"missing_count\": null,\n",
              "    \"missing_percent\": null\n",
              "  },\n",
              "  \"success\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "house_data.expect_column_distinct_values_to_be_in_set(\"MSZoning\", [\"C (all)\", \"FV\", \"RH\", \"RL\", \"RM\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RoWb4s3NHhiI",
        "outputId": "d3912eb4-0b0f-4bd0-ec93-f1e5c24aa5bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"meta\": {},\n",
              "  \"expectation_config\": {\n",
              "    \"kwargs\": {\n",
              "      \"column\": \"GrLivArea\",\n",
              "      \"min_value\": 0,\n",
              "      \"max_value\": 10000,\n",
              "      \"result_format\": \"BASIC\"\n",
              "    },\n",
              "    \"meta\": {},\n",
              "    \"expectation_type\": \"expect_column_mean_to_be_between\"\n",
              "  },\n",
              "  \"exception_info\": {\n",
              "    \"raised_exception\": false,\n",
              "    \"exception_traceback\": null,\n",
              "    \"exception_message\": null\n",
              "  },\n",
              "  \"result\": {\n",
              "    \"observed_value\": 1515.463698630137,\n",
              "    \"element_count\": 1460,\n",
              "    \"missing_count\": null,\n",
              "    \"missing_percent\": null\n",
              "  },\n",
              "  \"success\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "house_data.expect_column_mean_to_be_between(\"GrLivArea\", 0, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5FscLwQhHhiI",
        "outputId": "59d90679-d9ad-4276-d118-82303b1ffb82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"ge_cloud_id\": null,\n",
              "  \"expectations\": [\n",
              "    {\n",
              "      \"kwargs\": {\n",
              "        \"column\": \"Id\"\n",
              "      },\n",
              "      \"meta\": {},\n",
              "      \"expectation_type\": \"expect_column_to_exist\"\n",
              "    },\n",
              "    {\n",
              "      \"kwargs\": {\n",
              "        \"column\": \"Id\"\n",
              "      },\n",
              "      \"meta\": {},\n",
              "      \"expectation_type\": \"expect_column_values_to_be_unique\"\n",
              "    },\n",
              "    {\n",
              "      \"kwargs\": {\n",
              "        \"column\": \"GrLivArea\",\n",
              "        \"min_value\": 0,\n",
              "        \"max_value\": 10000\n",
              "      },\n",
              "      \"meta\": {},\n",
              "      \"expectation_type\": \"expect_column_mean_to_be_between\"\n",
              "    },\n",
              "    {\n",
              "      \"kwargs\": {\n",
              "        \"column\": \"MSZoning\",\n",
              "        \"value_set\": [\n",
              "          \"C (all)\",\n",
              "          \"FV\",\n",
              "          \"RH\",\n",
              "          \"RL\",\n",
              "          \"RM\"\n",
              "        ]\n",
              "      },\n",
              "      \"meta\": {},\n",
              "      \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\"\n",
              "    }\n",
              "  ],\n",
              "  \"meta\": {\n",
              "    \"great_expectations_version\": \"0.15.18\"\n",
              "  },\n",
              "  \"expectation_suite_name\": \"default\",\n",
              "  \"data_asset_type\": \"Dataset\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# This will create an expectation suite from all the valid expectations we created above.\n",
        "house_data.get_expectation_suite()\n",
        "# If we want the non-valid expectations as well, we can use the `get_expectation_suite` method with the \n",
        "# `discard_failed_expectations` parameter set to True. If there are any duplicate expectations in the suite, \n",
        "# the duplicates will be discarded:\n",
        "# house_data.get_expectation_suite(discard_failed_expectations=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Pj0y7M-cHhiI"
      },
      "outputs": [],
      "source": [
        "# This line will save the expectation suite to the data context\n",
        "expectation_suite_name = \"my_expectations1\"\n",
        "context.save_expectation_suite(house_data.get_expectation_suite(), expectation_suite_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4k01glg9HhiJ"
      },
      "source": [
        "### Exercise 1\n",
        "Check the following expectations to see if they are valid on the house_data dataframe:\n",
        "\n",
        "(Not all the expectations were included in the examples above. You can find more expectations in the [expectations directory](https://greatexpectations.io/expectations).)\n",
        "1. `Street` column should be a string.\n",
        "2. `LandContour` column cannot be null.\n",
        "3. `YearBuilt` minimal value should be between 1700 and 1900.\n",
        "4. `LotArea` median value should be between 5000 and 15000.\n",
        "5. The most common values in `SaleType` must be either `WD` or `New`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZWJGTgzUHhiJ",
        "outputId": "4853f1ee-9213-48ff-cbd9-ffaab7101354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"meta\": {},\n",
              "  \"expectation_config\": {\n",
              "    \"kwargs\": {\n",
              "      \"column\": \"SaleType\",\n",
              "      \"value_set\": [\n",
              "        \"WD\",\n",
              "        \"New\"\n",
              "      ],\n",
              "      \"result_format\": \"BASIC\"\n",
              "    },\n",
              "    \"meta\": {},\n",
              "    \"expectation_type\": \"expect_column_most_common_value_to_be_in_set\"\n",
              "  },\n",
              "  \"exception_info\": {\n",
              "    \"raised_exception\": false,\n",
              "    \"exception_traceback\": null,\n",
              "    \"exception_message\": null\n",
              "  },\n",
              "  \"result\": {\n",
              "    \"observed_value\": [\n",
              "      \"WD\"\n",
              "    ],\n",
              "    \"element_count\": 1460,\n",
              "    \"missing_count\": null,\n",
              "    \"missing_percent\": null\n",
              "  },\n",
              "  \"success\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# your answers here:\n",
        "#house_data.expect_column_values_to_be_of_type(\"Street\", 'str')\n",
        "#house_data.expect_column_values_to_not_be_null('LandContour')\n",
        "#house_data.expect_column_min_to_be_between(\"YearBuilt\", 1700, 1900)\n",
        "#house_data.expect_column_median_to_be_between(\"LotArea\", 5000, 15000)\n",
        "house_data.expect_column_most_common_value_to_be_in_set(\"SaleType\", ['WD', 'New'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5UfkiHqJHhiJ"
      },
      "source": [
        "*Exercise solutions can be found in the exercise solutions file in the current directory.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kT7encBsHhiK"
      },
      "source": [
        "### 4. Validate the Data\n",
        "We will now validate the test data using the expectations we have created for the train data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UC2tT0b-HhiK"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://docs.greatexpectations.io/assets/images/how_a_checkpoint_works-10e7fda2c9013d98a36c1d8526036764.png\" width=\"1000\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HqtTHC5OHhiK"
      },
      "outputs": [],
      "source": [
        "checkpoint_name = \"data_batch_appended\"\n",
        "# Checkpoint - The primary means for validating data in a production deployment of Great Expectations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KHb0pAyXHhiK"
      },
      "outputs": [],
      "source": [
        "checkpoint_config = {\n",
        "    \"name\": checkpoint_name,\n",
        "    \"config_version\": 1,\n",
        "    \"class_name\": \"SimpleCheckpoint\",\n",
        "    \"validations\": [\n",
        "        {\n",
        "            \"batch_request\": {\n",
        "                \"datasource_name\": datasource_name,\n",
        "                \"data_connector_name\": runtime_data_connector_name,\n",
        "                \"data_asset_name\": data_asset_name,\n",
        "            },\n",
        "            \"expectation_suite_name\": expectation_suite_name,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "context.add_checkpoint(**checkpoint_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NJMkMrV9HhiK"
      },
      "source": [
        "Looking at the dictionary returned by the `add_checkpoint` methods we can see what are the actions performed every time the checkpoint will run:\n",
        "1. Store validation result.\n",
        "2. Store evaluation parameters.\n",
        "3. Update data docs. (we will look at the data docs later in this notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-4QR4fpXHhiL"
      },
      "outputs": [],
      "source": [
        "house_data_test = ge.read_csv(\"https://github.com/NatanMish/data_validation/blob/a77b247b25c6622ce0c8f8cbc505228161c31a3c/data/test.csv?raw=true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OXlAFJ1DHhiL"
      },
      "outputs": [],
      "source": [
        "results = context.run_checkpoint(\n",
        "    checkpoint_name=checkpoint_name,\n",
        "    batch_request={\n",
        "        \"runtime_parameters\": {\"batch_data\": house_data_test},\n",
        "        \"batch_identifiers\": {\n",
        "            batch_identifier_name: \"step_1\"\n",
        "        },\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TByKqJMNHhiL"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the validation result object we got:\n",
        "run_identifier = next(iter(results['run_results']))\n",
        "results['run_results'][run_identifier]['validation_result']['statistics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FD4zSrsRHhiL"
      },
      "outputs": [],
      "source": [
        "# Here is an example of one of the validations on one of the expectations. The check has passed and there are some \n",
        "# useful extra details too.\n",
        "results['run_results'][run_identifier]['validation_result']['results'][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gOfTXTd8HhiL"
      },
      "source": [
        "#### How does an invalid data checkpoint look like?\n",
        "Glad you asked, let's inject a duplicate value to our `Id` column to see how it behaves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZQ3DRQrOHhiM"
      },
      "outputs": [],
      "source": [
        "# This will create a duplicate id value for two separate records\n",
        "house_data_test.at[0, 'Id'] = 1462"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vQ6HplhYHhiM"
      },
      "outputs": [],
      "source": [
        "validator = {\n",
        "            \"batch_request\": {\n",
        "                \"datasource_name\": datasource_name,\n",
        "                \"data_connector_name\": runtime_data_connector_name,\n",
        "                \"data_asset_name\": data_asset_name,\n",
        "            },\n",
        "            \"expectation_suite_name\": expectation_suite_name,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ovF9tbOzHhiM"
      },
      "outputs": [],
      "source": [
        "# Notice how we've adde the runtime configuration and result format = COMPLETE, this will give us the unexpected index list\n",
        "\n",
        "bad_data_checkpoint_name = \"my_bad_data_checkpoint\"\n",
        "bad_data_checkpoint_config = {\n",
        "    \"name\": bad_data_checkpoint_name,\n",
        "    \"config_version\": 1,\n",
        "    \"class_name\": \"SimpleCheckpoint\",\n",
        "    \"runtime_configuration\": {\n",
        "        \"result_format\": {\n",
        "            \"result_format\": \"COMPLETE\", # BASIC\n",
        "            \"include_unexpected_rows\": True\n",
        "        }\n",
        "    },\n",
        "    \"validations\": [\n",
        "      validator \n",
        "    ],\n",
        "}\n",
        "context.add_checkpoint(**bad_data_checkpoint_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ehooRuOQHhiN"
      },
      "outputs": [],
      "source": [
        "results_bad_data_checkpoint = context.run_checkpoint(\n",
        "    checkpoint_name=bad_data_checkpoint_name,\n",
        "    batch_request={\n",
        "        \"runtime_parameters\": {\"batch_data\": house_data_test},\n",
        "        \"batch_identifiers\": {\n",
        "            batch_identifier_name: \"step_2\"\n",
        "        },\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mbHOS3d4HhiN"
      },
      "outputs": [],
      "source": [
        "# As expected, not all expectations were successful.\n",
        "bad_data_run_identifier = next(iter(results_bad_data_checkpoint['run_results']))\n",
        "results_bad_data_checkpoint['run_results'][bad_data_run_identifier]['validation_result']['statistics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4IXGKtwSHhiN"
      },
      "outputs": [],
      "source": [
        "# And here is the summary for the failed expectation\n",
        "results_bad_data_checkpoint['run_results'][bad_data_run_identifier]['validation_result']['results'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "H0rUalnpHhiN"
      },
      "outputs": [],
      "source": [
        "# We can unpack the unexpected data indices list\n",
        "unexpected_data_indices = results_bad_data_checkpoint['run_results'][bad_data_run_identifier]['validation_result']['results'][1]['result']['unexpected_index_list']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EsgflSq2HhiO"
      },
      "outputs": [],
      "source": [
        "# And then filter the invalid data from the dataframe\n",
        "filtered_house_data_test = house_data_test[~house_data_test.index.isin(unexpected_data_indices)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V5Bar-9THhiO"
      },
      "source": [
        "### 6. Create Data Docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IPtqTZprHhiO"
      },
      "outputs": [],
      "source": [
        "# Build the data docs, in Jupyter a new tab will open up with the data docs page\n",
        "!echo y | great_expectations docs build --site-name local_site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hQ8PFPk2HhiO"
      },
      "outputs": [],
      "source": [
        "# in Google Colab you'll have to download the folder and open it up locally in /uncommited/data_docs/local_site/index.html. \n",
        "# Uncomment and run the 3 lines below:\n",
        "# from google.colab import files\n",
        "# !zip -r data_docs.zip great_expectations/uncommitted/data_docs\n",
        "# files.download('data_docs.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CZ7TAarwHhiO"
      },
      "source": [
        "### 7. Using the User Configurable Profiler to compare two tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Z48VLxeTHhiP"
      },
      "source": [
        "The configurable profiler feature provided by Great Expectations can be a great place to start with a never seen before dataset. It creates automated Expectations\n",
        "based on the values and aggregates of the data. Another way to utilise it is to create automated expectations on one table of data, and then validate them against\n",
        "a second table, which allows a deep comparison between the two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qrp3xOtiHhiP"
      },
      "outputs": [],
      "source": [
        "# Exclude most columns so the expectation creation process is not too long\n",
        "exclude_column_names = ['LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', \"LotConfig\", \"LandSlope\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"OverallQual\", \"OverallCond\", \"YearBuilt\", \"YearRemodAdd\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"MasVnrArea\", \"ExterQual\", \"ExterCond\", \"Foundation\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinSF1\", \"BsmtFinType2\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"Heating\", \"HeatingQC\", \"CentralAir\", \"Electrical\", \"PoolArea\", \"PoolQC\", \"LowQualFinSF\", \"GrLivArea\", \"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \"HalfBath\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"KitchenQual\", \"TotRmsAbvGrd\", \"Functional\", \"Fireplaces\", \"FireplaceQu\", \"GarageType\", \"GarageYrBlt\", \"GarageFinish\", \"GarageCars\", \"GarageArea\", \"GarageQual\", \"GarageCond\", \"PavedDrive\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\", \"Fence\", \"MiscFeature\", \"MiscVal\", \"MoSold\", \"YrSold\", \"SaleType\", \"SaleCondition\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcC9zvG3HhiQ"
      },
      "outputs": [],
      "source": [
        "house_data.drop(exclude_column_names, axis=1).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AhppSXE1HhiQ"
      },
      "outputs": [],
      "source": [
        "runtime_batch_request = RuntimeBatchRequest(\n",
        "    datasource_name=datasource_name,\n",
        "    data_connector_name=runtime_data_connector_name,\n",
        "    data_asset_name=data_asset_name,\n",
        "    runtime_parameters={\"batch_data\": house_data.drop(exclude_column_names, axis=1)},\n",
        "    batch_identifiers={\n",
        "        batch_identifier_name: \"step_3\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3kt-hMxaHhiR"
      },
      "outputs": [],
      "source": [
        "# Create a validator instance from the batch request\n",
        "validator = context.get_validator(batch_request=runtime_batch_request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gp_Y-H2SHhiR"
      },
      "outputs": [],
      "source": [
        "profiler = UserConfigurableProfiler(\n",
        "    profile_dataset=validator,\n",
        "    excluded_expectations=None,\n",
        "    ignored_columns=exclude_column_names,\n",
        "    not_null_only=False,\n",
        "    primary_or_compound_key=None,\n",
        "    semantic_types_dict=None,\n",
        "    table_expectations_only=False,\n",
        "    value_set_threshold=\"MANY\",\n",
        ")\n",
        "suite = profiler.build_suite()\n",
        "validator.expectation_suite = suite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ouvnGzRWHhiR"
      },
      "outputs": [],
      "source": [
        "validator.save_expectation_suite(discard_failed_expectations=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-kZc4ZSiHhiR"
      },
      "outputs": [],
      "source": [
        "# Create a checkpoint based on the expectation suite built using the profiler on the house_data table, and use it to validate the house_data_test\n",
        "profiled_validator_checkpoint = \"profiled_validator\"\n",
        "checkpoint_config = {\n",
        "    \"name\": profiled_validator_checkpoint,\n",
        "    \"config_version\": 1,\n",
        "    \"class_name\": \"SimpleCheckpoint\",\n",
        "    \"validations\": [\n",
        "        {\n",
        "            \"batch_request\": {\n",
        "                \"datasource_name\": datasource_name,\n",
        "                \"data_connector_name\": runtime_data_connector_name,\n",
        "                \"data_asset_name\": data_asset_name,\n",
        "            },\n",
        "            \"expectation_suite_name\": \"default\",\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "context.add_checkpoint(**checkpoint_config)\n",
        "results_profiled_checkpoint = context.run_checkpoint(\n",
        "    checkpoint_name=profiled_validator_checkpoint,\n",
        "    batch_request={\n",
        "        \"runtime_parameters\": {\"batch_data\": house_data_test.drop(exclude_column_names, axis=1)},\n",
        "        \"batch_identifiers\": {\n",
        "            batch_identifier_name: \"step_4\"\n",
        "        },\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s67JXfCIHhiS"
      },
      "outputs": [],
      "source": [
        "# Run and open the data docs to look at the comparison summary\n",
        "context.build_data_docs()\n",
        "\n",
        "validation_result_identifier = results_profiled_checkpoint.list_validation_result_identifiers()[0]\n",
        "context.open_data_docs(resource_identifier=validation_result_identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlLp2uWoHhiS"
      },
      "outputs": [],
      "source": [
        "# in Google Colab you'll have to download the folder and open it up locally in /uncommited/data_docs/local_site/index.html. \n",
        "# Uncomment and run the 3 lines below:\n",
        "# from google.colab import files\n",
        "# !zip -r data_docs.zip great_expectations/uncommitted/data_docs\n",
        "# files.download('data_docs.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GCSMt2l-HhiS"
      },
      "source": [
        "### 8. Custom Expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kmFXjP0-HhiS"
      },
      "source": [
        "We will explain the process of creating a custom expectation using an example. A common method to check for outliers is to calculate the Z-score for each value\n",
        "and signal out any value with a Z-score above 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JyFWMG2jHhiS"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://datasciencelk.com/wp-content/uploads/2020/05/normal-plot-with-sigma.jpg\" width=\"600\"/>\n",
        "<img src=\"https://www.gstatic.com/education/formulas2/443397389/en/z_score.svg\" width=200/>\n",
        "</div>\n",
        "<a href=\"https://datasciencelk.com/normal-distribution-z-scores-standardization-explained/\">https://datasciencelk.com/normal-distribution-z-scores-standardization-explained/</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HVxRSvxCHhiT"
      },
      "source": [
        "Creating a custom expectation requires creating a separate module, we will use a template provided by Great Expectations and make minor adjustments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fQi81BQoHhiT"
      },
      "outputs": [],
      "source": [
        "%%writefile expect_column_z_score_lower_than_3.py\n",
        "\"\"\"\n",
        "This is a template for creating custom ColumnExpectations.\n",
        "For detailed instructions on how to use it, please see:\n",
        "    https://docs.greatexpectations.io/docs/guides/expectations/creating_custom_expectations/how_to_create_custom_column_aggregate_expectations\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from typing import Callable, Dict, Optional\n",
        "\n",
        "from numpy import array\n",
        "\n",
        "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
        "from great_expectations.execution_engine import (\n",
        "    PandasExecutionEngine,\n",
        "    SparkDFExecutionEngine,\n",
        "    SqlAlchemyExecutionEngine,\n",
        ")\n",
        "from great_expectations.execution_engine.execution_engine import (\n",
        "    ExecutionEngine,\n",
        "    MetricDomainTypes,\n",
        "    MetricPartialFunctionTypes,\n",
        ")\n",
        "from great_expectations.expectations.expectation import (\n",
        "    ColumnMapExpectation,\n",
        "    ExpectationValidationResult,\n",
        ")\n",
        "from great_expectations.expectations.metrics import (\n",
        "    ColumnMapMetricProvider,\n",
        "    column_condition_partial,\n",
        "    metric_partial,\n",
        ")\n",
        "from great_expectations.expectations.metrics.import_manager import F, sa\n",
        "from great_expectations.expectations.util import render_evaluation_parameter_string\n",
        "from great_expectations.render.renderer.renderer import renderer\n",
        "from great_expectations.render.types import (\n",
        "    CollapseContent,\n",
        "    RenderedStringTemplateContent,\n",
        ")\n",
        "from great_expectations.render.util import (\n",
        "    handle_strict_min_max,\n",
        "    parse_row_condition_string_pandas_engine,\n",
        "    substitute_none_for_missing,\n",
        ")\n",
        "from great_expectations.validator.metric_configuration import MetricConfiguration\n",
        "\n",
        "    \n",
        "# This class defines a Metric to support your Expectation.\n",
        "# For most ColumnMapExpectations, the main business logic for calculation will live in this class.\n",
        "class ColumnValuesLowerThanZScoreOf3(ColumnMapMetricProvider):\n",
        "\n",
        "    # This is the id string that will be used to reference your metric.\n",
        "    condition_metric_name = \"column_values.lower_than_z_score_of_3\"\n",
        "\n",
        "    # This method implements the core logic for the PandasExecutionEngine\n",
        "    @column_condition_partial(engine=PandasExecutionEngine)\n",
        "    def _pandas(cls, column, **kwargs):\n",
        "        return abs((abs(column.mean()) - abs(column))/column.std()) < 3\n",
        "\n",
        "\n",
        "# This class defines the Expectation itself\n",
        "class ExpectColumnZScoreLowerThan3(ColumnMapExpectation):\n",
        "    \"\"\"This expectation takes the input column, calculates the standarad deviation, mean for the entire column and then calculates the \n",
        "    Z-score for each value in the column. Any value with a Z-score larger than 3 is considered an outlier. Z-score is defined as: \n",
        "    (value-column_mean)/standard_deviation\"\"\"\n",
        "\n",
        "    # These examples will be shown in the public gallery.\n",
        "    # They will also be executed as unit tests for your Expectation.\n",
        "    examples = [\n",
        "        {\n",
        "            \"data\": {\"x\": [1, 2, 3, 4, 5], \"y\": [-15, 2, 3, 4, 5]},\n",
        "            \"tests\": [\n",
        "                {\n",
        "                    \"title\": \"basic_positive_test\",\n",
        "                    \"exact_match_out\": False,\n",
        "                    \"include_in_gallery\": True,\n",
        "                    \"in\": {\n",
        "                        \"column\": \"x\",\n",
        "                    },\n",
        "                    \"out\": {\"success\": True},\n",
        "                },\n",
        "                {\n",
        "                    \"title\": \"basic_negative_test\",\n",
        "                    \"exact_match_out\": False,\n",
        "                    \"include_in_gallery\": True,\n",
        "                    \"in\": {\n",
        "                        \"column\": \"y\",\n",
        "                    },\n",
        "                    \"out\": {\"success\": False},\n",
        "                },\n",
        "            ],\n",
        "            \"test_backends\": [\n",
        "                {\n",
        "                    \"backend\": \"pandas\",\n",
        "                    \"dialects\": None,\n",
        "                },\n",
        "                # {\n",
        "                #     \"backend\": \"sqlalchemy\",\n",
        "                #     \"dialects\": [\"sqlite\", \"postgresql\"],\n",
        "                # },\n",
        "                # {\n",
        "                #     \"backend\": \"spark\",\n",
        "                #     \"dialects\": None,\n",
        "                # },\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # This is the id string of the Metric used by this Expectation.\n",
        "    # For most Expectations, it will be the same as the `condition_metric_name` defined in your Metric class above.\n",
        "    map_metric = \"column_values.lower_than_z_score_of_3\"\n",
        "\n",
        "    # This is a list of parameter names that can affect whether the Expectation evaluates to True or False\n",
        "    # Please see https://docs.greatexpectations.io/en/latest/reference/core_concepts/expectations/expectations.html#expectation-concepts-domain-and-success-keys\n",
        "    # for more information about domain and success keys, and other arguments to Expectations\n",
        "    success_keys = (\"mostly\",)\n",
        "\n",
        "    # This dictionary contains default values for any parameters that should have default values\n",
        "    default_kwarg_values = {}\n",
        "\n",
        "    @renderer(renderer_type=\"renderer.diagnostic.observed_value\")\n",
        "    @render_evaluation_parameter_string\n",
        "    def _diagnostic_observed_value_renderer(\n",
        "        cls,\n",
        "        configuration: ExpectationConfiguration = None,\n",
        "        result: ExpectationValidationResult = None,\n",
        "        language: str = None,\n",
        "        runtime_configuration: dict = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        assert result, \"Must provide a result object.\"\n",
        "\n",
        "        result_dict = result.result\n",
        "        if result_dict is None:\n",
        "            return \"--\"\n",
        "\n",
        "        if result_dict.get(\"observed_value\"):\n",
        "            observed_value = result_dict.get(\"observed_value\")\n",
        "            if isinstance(observed_value, (int, float)) and not isinstance(\n",
        "                observed_value, bool\n",
        "            ):\n",
        "                return num_to_str(observed_value, precision=10, use_locale=True)\n",
        "            return str(observed_value)\n",
        "        elif result_dict.get(\"unexpected_percent\") is not None:\n",
        "            return (\n",
        "                num_to_str(result_dict.get(\"unexpected_percent\"), precision=5)\n",
        "                + \"% unexpected\"\n",
        "            )\n",
        "        else:\n",
        "            return \"--\"\n",
        "\n",
        "    @renderer(renderer_type=\"renderer.diagnostic.unexpected_statement\")\n",
        "    @render_evaluation_parameter_string\n",
        "    def _diagnostic_unexpected_statement_renderer(\n",
        "        cls,\n",
        "        configuration: ExpectationConfiguration = None,\n",
        "        result: ExpectationValidationResult = None,\n",
        "        language: str = None,\n",
        "        runtime_configuration: dict = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        assert result, \"Must provide a result object.\"\n",
        "\n",
        "        success = result.success\n",
        "        result = result.result\n",
        "\n",
        "        if result.exception_info[\"raised_exception\"]:\n",
        "            exception_message_template_str = (\n",
        "                \"\\n\\n$expectation_type raised an exception:\\n$exception_message\"\n",
        "            )\n",
        "\n",
        "            exception_message = RenderedStringTemplateContent(\n",
        "                **{\n",
        "                    \"content_block_type\": \"string_template\",\n",
        "                    \"string_template\": {\n",
        "                        \"template\": exception_message_template_str,\n",
        "                        \"params\": {\n",
        "                            \"expectation_type\": result.expectation_config.expectation_type,\n",
        "                            \"exception_message\": result.exception_info[\n",
        "                                \"exception_message\"\n",
        "                            ],\n",
        "                        },\n",
        "                        \"tag\": \"strong\",\n",
        "                        \"styling\": {\n",
        "                            \"classes\": [\"text-danger\"],\n",
        "                            \"params\": {\n",
        "                                \"exception_message\": {\"tag\": \"code\"},\n",
        "                                \"expectation_type\": {\n",
        "                                    \"classes\": [\"badge\", \"badge-danger\", \"mb-2\"]\n",
        "                                },\n",
        "                            },\n",
        "                        },\n",
        "                    },\n",
        "                }\n",
        "            )\n",
        "\n",
        "            exception_traceback_collapse = CollapseContent(\n",
        "                **{\n",
        "                    \"collapse_toggle_link\": \"Show exception traceback...\",\n",
        "                    \"collapse\": [\n",
        "                        RenderedStringTemplateContent(\n",
        "                            **{\n",
        "                                \"content_block_type\": \"string_template\",\n",
        "                                \"string_template\": {\n",
        "                                    \"template\": result.exception_info[\n",
        "                                        \"exception_traceback\"\n",
        "                                    ],\n",
        "                                    \"tag\": \"code\",\n",
        "                                },\n",
        "                            }\n",
        "                        )\n",
        "                    ],\n",
        "                }\n",
        "            )\n",
        "\n",
        "            return [exception_message, exception_traceback_collapse]\n",
        "\n",
        "        if success or not result_dict.get(\"unexpected_count\"):\n",
        "            return []\n",
        "        else:\n",
        "            unexpected_count = num_to_str(\n",
        "                result_dict[\"unexpected_count\"], use_locale=True, precision=20\n",
        "            )\n",
        "            unexpected_percent = (\n",
        "                num_to_str(result_dict[\"unexpected_percent\"], precision=4) + \"%\"\n",
        "            )\n",
        "            element_count = num_to_str(\n",
        "                result_dict[\"element_count\"], use_locale=True, precision=20\n",
        "            )\n",
        "\n",
        "            template_str = (\n",
        "                \"\\n\\n$unexpected_count unexpected values found. \"\n",
        "                \"$unexpected_percent of $element_count total rows.\"\n",
        "            )\n",
        "\n",
        "            return [\n",
        "                RenderedStringTemplateContent(\n",
        "                    **{\n",
        "                        \"content_block_type\": \"string_template\",\n",
        "                        \"string_template\": {\n",
        "                            \"template\": template_str,\n",
        "                            \"params\": {\n",
        "                                \"unexpected_count\": unexpected_count,\n",
        "                                \"unexpected_percent\": unexpected_percent,\n",
        "                                \"element_count\": element_count,\n",
        "                            },\n",
        "                            \"tag\": \"strong\",\n",
        "                            \"styling\": {\"classes\": [\"text-danger\"]},\n",
        "                        },\n",
        "                    }\n",
        "                )\n",
        "            ]\n",
        "\n",
        "    @renderer(renderer_type=\"renderer.diagnostic.unexpected_table\")\n",
        "    @render_evaluation_parameter_string\n",
        "    def _diagnostic_unexpected_table_renderer(\n",
        "        cls,\n",
        "        configuration: ExpectationConfiguration = None,\n",
        "        result: ExpectationValidationResult = None,\n",
        "        language: str = None,\n",
        "        runtime_configuration: dict = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        try:\n",
        "            result_dict = result.result\n",
        "        except KeyError:\n",
        "            return None\n",
        "\n",
        "        if result_dict is None:\n",
        "            return None\n",
        "\n",
        "        if not result_dict.get(\"partial_unexpected_list\") and not result_dict.get(\n",
        "            \"partial_unexpected_counts\"\n",
        "        ):\n",
        "            return None\n",
        "\n",
        "        table_rows = []\n",
        "\n",
        "        if result_dict.get(\"partial_unexpected_counts\"):\n",
        "            total_count = 0\n",
        "            for unexpected_count_dict in result_dict.get(\"partial_unexpected_counts\"):\n",
        "                value = unexpected_count_dict.get(\"value\")\n",
        "                count = unexpected_count_dict.get(\"count\")\n",
        "                total_count += count\n",
        "                if value is not None and value != \"\":\n",
        "                    table_rows.append([value, count])\n",
        "                elif value == \"\":\n",
        "                    table_rows.append([\"EMPTY\", count])\n",
        "                else:\n",
        "                    table_rows.append([\"null\", count])\n",
        "\n",
        "            if total_count == result_dict.get(\"unexpected_count\"):\n",
        "                header_row = [\"Unexpected Value\", \"Count\"]\n",
        "            else:\n",
        "                header_row = [\"Sampled Unexpected Values\"]\n",
        "                table_rows = [[row[0]] for row in table_rows]\n",
        "\n",
        "        else:\n",
        "            header_row = [\"Sampled Unexpected Values\"]\n",
        "            sampled_values_set = set()\n",
        "            for unexpected_value in result_dict.get(\"partial_unexpected_list\"):\n",
        "                if unexpected_value:\n",
        "                    string_unexpected_value = str(unexpected_value)\n",
        "                elif unexpected_value == \"\":\n",
        "                    string_unexpected_value = \"EMPTY\"\n",
        "                else:\n",
        "                    string_unexpected_value = \"null\"\n",
        "                if string_unexpected_value not in sampled_values_set:\n",
        "                    table_rows.append([unexpected_value])\n",
        "                    sampled_values_set.add(string_unexpected_value)\n",
        "\n",
        "        unexpected_table_content_block = RenderedTableContent(\n",
        "            **{\n",
        "                \"content_block_type\": \"table\",\n",
        "                \"table\": table_rows,\n",
        "                \"header_row\": header_row,\n",
        "                \"styling\": {\n",
        "                    \"body\": {\"classes\": [\"table-bordered\", \"table-sm\", \"mt-3\"]}\n",
        "                },\n",
        "            }\n",
        "        )\n",
        "\n",
        "        return unexpected_table_content_block\n",
        "\n",
        "    # This dictionary contains metadata for display in the public gallery\n",
        "    library_metadata = {\n",
        "        \"tags\": [],\n",
        "        \"contributors\": [\"@NatanMish\"],\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ExpectColumnZScoreLowerThan3().print_diagnostic_checklist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6IVaAc5pHhiU"
      },
      "outputs": [],
      "source": [
        "# Running this module as is will run a series of checks to see whether the expectation can be used.\n",
        "!python expect_column_z_score_lower_than_3.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hy4bbGb_HhiU"
      },
      "outputs": [],
      "source": [
        "from expect_column_z_score_lower_than_3 import ExpectColumnZScoreLowerThan3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AWzLwqf4HhiU"
      },
      "outputs": [],
      "source": [
        "validator.expect_column_z_score_lower_than3(column=\"SalePrice\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YgOeLwymHhiU"
      },
      "outputs": [],
      "source": [
        "validator.expect_column_value_z_scores_to_be_less_than(\"SalePrice\", 3, double_sided=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IKzc1GD6HhiV"
      },
      "source": [
        "### Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rbH-ZNCuHhiV"
      },
      "source": [
        "In this exercise we will create a custom expectation using the ColumnPairMapExpectation template. This template is useful for creating an expectation that compares values from two columns. The expectation we are going to create is \"Expect Proportional Floor SF(square feet) Ratio\". This expectation will pick up two columns - `1stFlrSF` and `2ndFlrSF` and validate that the 2nd floor is not more than twice larger than the first one.\n",
        "\n",
        "To build this custom expectation follow these steps:\n",
        "1. In line 37, insert a Pandas expression that returns a Series of booleans: True if the expectation holds, meaning the ratio between the 2nd floor SF to the 1st one is less than 2, and False otherwise.\n",
        "2. In lines 48-49, insert values for the two lists that are going to be used in the tests. col_a is for the 1st floor SF and col_b is for the 2nd floor SF. Notice there is one positive scenario and one negative scenario. The `mostly` success key is set at 0.6 for the succesful scenario and 1 for the failed scenario, which means that in your lists at least 60% of the pairs should be valid according to the logic. For example, two valid pairs and one non-valid.\n",
        "3. Run the rest of the cells and see that checks are passing and the results you get are as expected.\n",
        "\n",
        "To add line numbers in Google Colab select Tools -> Settings -> Editor -> show line numbers\n",
        "To add line numbers in Jupyter select view -> toggle line numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "nMAG932PHhiV"
      },
      "source": [
        "**For the purpose of this exercise, column A is the 1st flor SF and column B is the 2nd floor SF.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Q4Zw_XTUHhiV"
      },
      "outputs": [],
      "source": [
        "%%writefile expect_proportional_floor_sf_ratio.py\n",
        "from typing import Dict, Optional\n",
        "\n",
        "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
        "from great_expectations.exceptions.exceptions import (\n",
        "    InvalidExpectationConfigurationError,\n",
        ")\n",
        "from great_expectations.execution_engine import (\n",
        "    ExecutionEngine,\n",
        "    PandasExecutionEngine,\n",
        "    SparkDFExecutionEngine,\n",
        "    SqlAlchemyExecutionEngine,\n",
        ")\n",
        "from great_expectations.expectations.expectation import (\n",
        "    ColumnPairMapExpectation,\n",
        "    ExpectationValidationResult,\n",
        ")\n",
        "from great_expectations.expectations.metrics.import_manager import F, sa\n",
        "from great_expectations.expectations.metrics.map_metric_provider import (\n",
        "    ColumnPairMapMetricProvider,\n",
        "    column_pair_condition_partial,\n",
        ")\n",
        "from great_expectations.validator.metric_configuration import MetricConfiguration\n",
        "\n",
        "\n",
        "class ColumnFloorsSquareFeetComparison(ColumnPairMapMetricProvider):\n",
        "    \"\"\"MetricProvider Class for columns floors square feet comparison\"\"\"\n",
        "    condition_metric_name = \"column_pair_values.floors_square_feet_ratio\"\n",
        "    condition_domain_keys = (\n",
        "        \"column_A\",\n",
        "        \"column_B\",\n",
        "    )\n",
        "    condition_value_keys = ()\n",
        "    @column_pair_condition_partial(engine=PandasExecutionEngine)\n",
        "    def _pandas(cls, column_A, column_B, **kwargs):\n",
        "        # This methold should return a Pandas series of booleans\n",
        "        return <YOUR PANDAS EXPRESSION HERE>\n",
        "\n",
        "\n",
        "class ExpectProportionalFloorDifference(ColumnPairMapExpectation):\n",
        "    \"\"\"Expect house 2nd floor to be no more than twice larger than the 1st floor\"\"\"\n",
        "    map_metric = \"column_pair_values.floors_square_feet_ratio\"\n",
        "    # These examples will be shown in the public gallery.\n",
        "    # They will also be executed as unit tests for your Expectation.\n",
        "    examples = [\n",
        "        {\n",
        "            \"data\": {\n",
        "                \"col_a\": [<test values for 1st floor SF>],\n",
        "                \"col_b\": [<test values for 2nd floor SF>],\n",
        "            },\n",
        "            \"tests\": [\n",
        "                {\n",
        "                    \"title\": \"basic_positive_test\",\n",
        "                    \"exact_match_out\": False,\n",
        "                    \"include_in_gallery\": True,\n",
        "                    \"in\": {\"column_A\": \"col_a\", \"column_B\": \"col_b\", \"mostly\": 0.6},\n",
        "                    \"out\": {\n",
        "                        \"success\": True,\n",
        "                    },\n",
        "                },\n",
        "                {\n",
        "                    \"title\": \"basic_negative_test\",\n",
        "                    \"exact_match_out\": False,\n",
        "                    \"include_in_gallery\": True,\n",
        "                    \"in\": {\"column_A\": \"col_a\", \"column_B\": \"col_b\", \"mostly\": 1},\n",
        "                    \"out\": {\n",
        "                        \"success\": False,\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    # Setting necessary computation metric dependencies and defining kwargs, as well as assigning kwargs default values\n",
        "    success_keys = (\n",
        "        \"column_A\",\n",
        "        \"column_B\",\n",
        "        \"mostly\",\n",
        "    )\n",
        "\n",
        "    default_kwarg_values = {\n",
        "        \"row_condition\": None,\n",
        "        \"condition_parser\": None,  # we expect this to be explicitly set whenever a row_condition is passed\n",
        "        \"mostly\": 1.0,\n",
        "        \"result_format\": \"COMPLETE\",\n",
        "        \"include_config\": True,\n",
        "        \"catch_exceptions\": False,\n",
        "    }\n",
        "    args_keys = (\n",
        "        \"column_A\",\n",
        "        \"column_B\",\n",
        "    )\n",
        "\n",
        "    def validate_configuration(\n",
        "        self, configuration: Optional[ExpectationConfiguration]\n",
        "    ) -> None:\n",
        "        super().validate_configuration(configuration)\n",
        "        if configuration is None:\n",
        "            configuration = self.configuration\n",
        "        try:\n",
        "            assert (\n",
        "                \"column_A\" in configuration.kwargs\n",
        "                and \"column_B\" in configuration.kwargs\n",
        "            ), \"both columns must be provided\"\n",
        "        except AssertionError as e:\n",
        "            raise InvalidExpectationConfigurationError(str(e))\n",
        "\n",
        "    # This dictionary contains metadata for display in the public gallery\n",
        "    library_metadata = {\n",
        "        \"tags\": [],\n",
        "        \"contributors\": [\"<YOUR GITHUB USERNAME HERE>\"],\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ExpectProportionalFloorDifference().print_diagnostic_checklist()\n",
        "# Note to users: code below this line is only for integration testing -- ignore!\n",
        "\n",
        "diagnostics = ExpectProportionalFloorDifference().run_diagnostics()\n",
        "\n",
        "for check in diagnostics[\"tests\"]:\n",
        "    assert check[\"test_passed\"] is True\n",
        "    assert check[\"error_diagnostics\"] is None\n",
        "\n",
        "for check in diagnostics[\"errors\"]:\n",
        "    assert check is None\n",
        "\n",
        "for check in diagnostics[\"maturity_checklist\"][\"experimental\"]:\n",
        "    if check[\"message\"] == \"Passes all linting checks\":\n",
        "        continue\n",
        "    assert check[\"passed\"] is True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pX26-KBhHhiW"
      },
      "outputs": [],
      "source": [
        "# Check that the module was configured correctly\n",
        "!python expect_proportional_floor_sf_ratio.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n7_Ch3_WHhiW"
      },
      "outputs": [],
      "source": [
        "from expect_proportional_floor_sf_ratio import ExpectProportionalFloorDifference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ShBL_8L9HhiW"
      },
      "outputs": [],
      "source": [
        "# Run the expectation using the validator instance, you should get one unexpected value in the results\n",
        "validator.expect_proportional_floor_difference(\"1stFlrSF\", \"2ndFlrSF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8g4gblO_HhiW"
      },
      "source": [
        "*Exercise solutions can be found in the exercise solutions file in the current directory.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efN-9OD4HhiW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}